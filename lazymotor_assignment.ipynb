{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtzwcsBzemR6",
        "outputId": "be2acf91-8ac9-43cd-d356-ee7e86ba74f9"
      },
      "outputs": [],
      "source": [
        "# !pip install whisper transformers edge-tts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0FEXFPkjSOH"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "from transformers import pipeline\n",
        "import edge_tts\n",
        "import asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Utz5fh43jf2f"
      },
      "outputs": [],
      "source": [
        "# Step 1: Voice-to-Text Conversion\n",
        "def audio_to_text(audio_file):\n",
        "    \"\"\"\n",
        "    Converts audio input to text using the Whisper model.\n",
        "\n",
        "    Parameters:\n",
        "    audio_file (str): Path to the audio file.\n",
        "\n",
        "    Returns:\n",
        "    str: Transcribed text from the audio.\n",
        "    \"\"\"\n",
        "    model = whisper.load_model(\"base\")  # Load the Whisper model\n",
        "    result = model.transcribe(audio_file, language='en')\n",
        "    return result['text']\n",
        "\n",
        "# Step 2: Text Input into LLM\n",
        "def get_llm_response(input_text):\n",
        "    \"\"\"\n",
        "    Generates a response from a Large Language Model (LLM) based on input text.\n",
        "\n",
        "    Parameters:\n",
        "    input_text (str): Input text for the LLM.\n",
        "\n",
        "    Returns:\n",
        "    str: Generated response from the LLM.\n",
        "    \"\"\"\n",
        "    llm = pipeline(\"text-generation\", model=\"gpt2\")  # Load the LLM model\n",
        "    response = llm(input_text, max_length=50, num_return_sequences=1)\n",
        "    return response[0]['generated_text']\n",
        "\n",
        "# Step 3: Text-to-Speech Conversion\n",
        "async def text_to_speech(text, output_file, pitch='0%', voice='en-US-JessaNeural', speed='0%'):\n",
        "    \"\"\"\n",
        "    Converts text to speech and saves it to an audio file.\n",
        "\n",
        "    Parameters:\n",
        "    text (str): Text to convert to speech.\n",
        "    output_file (str): Path to save the output audio file.\n",
        "    pitch (str): Pitch adjustment for the speech.\n",
        "    voice (str): Voice type for the speech.\n",
        "    speed (str): Speed adjustment for the speech.\n",
        "    \"\"\"\n",
        "    communicate = edge_tts.Communicate(text, voice=voice, rate=speed, pitch=pitch)\n",
        "    await communicate.save(output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjfDKyl4jn_u"
      },
      "outputs": [],
      "source": [
        "async def main(audio_file):\n",
        "    # Step 1: Convert audio to text\n",
        "    print(\"Converting audio to text...\")\n",
        "    text_output = audio_to_text(audio_file)\n",
        "    print(\"Transcribed Text:\", text_output)\n",
        "\n",
        "    # Step 2: Get response from LLM\n",
        "    print(\"Generating response from LLM...\")\n",
        "    llm_response = get_llm_response(text_output)\n",
        "    print(\"LLM Response:\", llm_response)\n",
        "\n",
        "    # Step 3: Convert response to speech\n",
        "    output_audio_file = \"output_audio.mp3\"\n",
        "    print(\"Converting response to speech...\")\n",
        "    await text_to_speech(llm_response, output_audio_file)\n",
        "    print(f\"Audio response saved to {output_audio_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "q4KtC77GjvUs",
        "outputId": "f3b23cb2-ed3b-453b-9853-4e0dd412df35"
      },
      "outputs": [],
      "source": [
        "# Replace with your audio file path\n",
        "audio_file_path = \"input.wav\"  # e.g., \"audio.wav\"\n",
        "\n",
        "# Run the main function\n",
        "await main(audio_file_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
